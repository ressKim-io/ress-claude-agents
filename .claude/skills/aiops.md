# AIOps ê°€ì´ë“œ

AI ê¸°ë°˜ IT ìš´ì˜: ì´ìƒ íƒì§€, ê·¼ë³¸ ì›ì¸ ë¶„ì„, ìë™ ë³µêµ¬

## Quick Reference (ê²°ì • íŠ¸ë¦¬)

```
AIOps ë„ì… ë‹¨ê³„?
    â”‚
    â”œâ”€ 1ë‹¨ê³„: ë°ì´í„° ìˆ˜ì§‘ â”€â”€â”€â”€> OpenTelemetry í‘œì¤€í™”
    â”‚       â”‚
    â”‚       â”œâ”€ Metrics â”€â”€â”€â”€â”€â”€â”€> Prometheus
    â”‚       â”œâ”€ Logs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> Loki/Elasticsearch
    â”‚       â””â”€ Traces â”€â”€â”€â”€â”€â”€â”€â”€> Jaeger/Tempo
    â”‚
    â”œâ”€ 2ë‹¨ê³„: ì´ìƒ íƒì§€ â”€â”€â”€â”€â”€â”€> ML ê¸°ë°˜ ë¶„ì„
    â”‚       â”‚
    â”‚       â”œâ”€ ì‹œê³„ì—´ ì´ìƒ â”€â”€â”€> Prophet/LSTM
    â”‚       â””â”€ ë¡œê·¸ ì´ìƒ â”€â”€â”€â”€â”€> Log Anomaly Detection
    â”‚
    â”œâ”€ 3ë‹¨ê³„: ê·¼ë³¸ ì›ì¸ ë¶„ì„ â”€> RCA Automation
    â”‚       â”‚
    â”‚       â”œâ”€ Causal AI â”€â”€â”€â”€â”€> ì˜ì¡´ì„± ê·¸ë˜í”„
    â”‚       â””â”€ LLM ë¶„ì„ â”€â”€â”€â”€â”€â”€> ì»¨í…ìŠ¤íŠ¸ ìš”ì•½
    â”‚
    â””â”€ 4ë‹¨ê³„: ìë™ ë³µêµ¬ â”€â”€â”€â”€â”€â”€> Self-Healing
            â”‚
            â”œâ”€ Runbook â”€â”€â”€â”€â”€â”€â”€> ìë™í™”ëœ ë³µêµ¬
            â””â”€ Policy â”€â”€â”€â”€â”€â”€â”€â”€> ì •ì±… ê¸°ë°˜ ì¡°ì¹˜
```

---

## CRITICAL: AIOps ì„±ìˆ™ë„ ëª¨ë¸

| Level | ë‹¨ê³„ | ìë™í™” ìˆ˜ì¤€ | ëª©í‘œ |
|-------|------|------------|------|
| **L1** | ë°˜ì‘ì  | ìˆ˜ë™ ë¶„ì„ | ì•Œë¦¼ ê´€ë¦¬ |
| **L2** | ì‚¬ì „ ì˜ˆë°©ì  | ì´ìƒ íƒì§€ | MTTD ë‹¨ì¶• |
| **L3** | ì˜ˆì¸¡ì  | RCA ìë™í™” | MTTR ë‹¨ì¶• |
| **L4** | ììœ¨ ìš´ì˜ | ìë™ ë³µêµ¬ | ë¬´ì¤‘ë‹¨ ìš´ì˜ |

### ì‹œì¥ í˜„í™© (2026)

| ì§€í‘œ | ê°’ | ì¶œì²˜ |
|------|-----|------|
| AIOps ì‹œì¥ ì„±ì¥ë¥  | 15% CAGR | Gartner |
| Observability ë„ì…ë¥  | 70% | Gartner |
| RCA ìë™í™” ì‚¬ìš© | 12% | LogicMonitor |
| ìë™ ë³µêµ¬ ì›í•˜ëŠ” ì¡°ì§ | 44% | LogicMonitor |

---

## OpenTelemetry í†µí•©

### OTel Collector ì„¤ì •

```yaml
apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: otel-collector
spec:
  mode: daemonset
  config:
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
      prometheus:
        config:
          scrape_configs:
            - job_name: 'kubernetes-pods'
              kubernetes_sd_configs:
                - role: pod

    processors:
      batch:
        timeout: 10s
        send_batch_size: 1024
      memory_limiter:
        check_interval: 1s
        limit_mib: 1000
      # AI ë¶„ì„ìš© ì†ì„± ì¶”ê°€
      attributes:
        actions:
          - key: ai.analysis.enabled
            value: true
            action: insert

    exporters:
      otlp:
        endpoint: "tempo:4317"
        tls:
          insecure: true
      prometheus:
        endpoint: "0.0.0.0:8889"
      loki:
        endpoint: "http://loki:3100/loki/api/v1/push"

    service:
      pipelines:
        traces:
          receivers: [otlp]
          processors: [memory_limiter, batch]
          exporters: [otlp]
        metrics:
          receivers: [otlp, prometheus]
          processors: [memory_limiter, batch]
          exporters: [prometheus]
        logs:
          receivers: [otlp]
          processors: [memory_limiter, batch, attributes]
          exporters: [loki]
```

---

## ì´ìƒ íƒì§€ (Anomaly Detection)

### Prometheus + Prophet í†µí•©

```python
# anomaly_detector.py
from prometheus_api_client import PrometheusConnect
from prophet import Prophet
import pandas as pd

class AnomalyDetector:
    def __init__(self, prometheus_url: str):
        self.prom = PrometheusConnect(url=prometheus_url)

    def detect_metric_anomaly(
        self,
        query: str,
        lookback_hours: int = 168,  # 1ì£¼
        sensitivity: float = 0.95
    ) -> list:
        # ë©”íŠ¸ë¦­ ì¡°íšŒ
        data = self.prom.custom_query_range(
            query=query,
            start_time=datetime.now() - timedelta(hours=lookback_hours),
            end_time=datetime.now(),
            step="5m"
        )

        # Prophet í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        df = pd.DataFrame({
            'ds': [datetime.fromtimestamp(d[0]) for d in data[0]['values']],
            'y': [float(d[1]) for d in data[0]['values']]
        })

        # ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡
        model = Prophet(interval_width=sensitivity)
        model.fit(df)
        forecast = model.predict(df)

        # ì´ìƒì¹˜ íƒì§€
        df['yhat'] = forecast['yhat']
        df['yhat_lower'] = forecast['yhat_lower']
        df['yhat_upper'] = forecast['yhat_upper']
        df['anomaly'] = (df['y'] < df['yhat_lower']) | (df['y'] > df['yhat_upper'])

        return df[df['anomaly']].to_dict('records')
```

### Grafana ML ê¸°ë°˜ ì´ìƒ íƒì§€

```yaml
# Grafana Alerting Rule with ML
apiVersion: 1
groups:
  - name: aiops-anomaly-detection
    folder: AIOps
    interval: 1m
    rules:
      - uid: anomaly-cpu
        title: CPU Anomaly Detection
        condition: C
        data:
          # A: í˜„ì¬ ê°’
          - refId: A
            relativeTimeRange:
              from: 600
              to: 0
            datasourceUid: prometheus
            model:
              expr: |
                avg(rate(container_cpu_usage_seconds_total{
                  namespace="production"
                }[5m])) by (pod)

          # B: ì˜ˆì¸¡ ê¸°ì¤€ì„  (ì´ë™ í‰ê·  + í‘œì¤€í¸ì°¨)
          - refId: B
            relativeTimeRange:
              from: 86400  # 24ì‹œê°„
              to: 0
            datasourceUid: prometheus
            model:
              expr: |
                avg_over_time(
                  avg(rate(container_cpu_usage_seconds_total{
                    namespace="production"
                  }[5m])) by (pod)[24h:5m]
                ) + 3 * stddev_over_time(
                  avg(rate(container_cpu_usage_seconds_total{
                    namespace="production"
                  }[5m])) by (pod)[24h:5m]
                )

          # C: ì´ìƒ ì—¬ë¶€ íŒë‹¨
          - refId: C
            datasourceUid: __expr__
            model:
              type: math
              expression: $A > $B
```

---

## ê·¼ë³¸ ì›ì¸ ë¶„ì„ (RCA)

### LLM ê¸°ë°˜ RCA ìë™í™”

```python
# rca_analyzer.py
from openai import OpenAI
from kubernetes import client, config
import json

class RCAAnalyzer:
    def __init__(self):
        self.llm = OpenAI()
        config.load_incluster_config()
        self.k8s = client.CoreV1Api()

    def analyze_incident(self, alert: dict) -> dict:
        # 1. ê´€ë ¨ ë°ì´í„° ìˆ˜ì§‘
        context = self._gather_context(alert)

        # 2. LLM ë¶„ì„
        analysis = self._llm_analyze(alert, context)

        # 3. ê²°ê³¼ êµ¬ì¡°í™”
        return {
            "incident": alert,
            "root_cause": analysis["root_cause"],
            "impact": analysis["impact"],
            "remediation": analysis["remediation"],
            "confidence": analysis["confidence"]
        }

    def _gather_context(self, alert: dict) -> dict:
        namespace = alert.get("namespace", "default")
        pod = alert.get("pod")

        context = {
            "events": [],
            "logs": [],
            "metrics": {}
        }

        # Kubernetes ì´ë²¤íŠ¸ ìˆ˜ì§‘
        events = self.k8s.list_namespaced_event(
            namespace=namespace,
            field_selector=f"involvedObject.name={pod}"
        )
        context["events"] = [
            {"reason": e.reason, "message": e.message, "time": str(e.last_timestamp)}
            for e in events.items[-10:]
        ]

        # Pod ìƒíƒœ ìˆ˜ì§‘
        pod_obj = self.k8s.read_namespaced_pod(name=pod, namespace=namespace)
        context["pod_status"] = {
            "phase": pod_obj.status.phase,
            "conditions": [
                {"type": c.type, "status": c.status, "reason": c.reason}
                for c in (pod_obj.status.conditions or [])
            ]
        }

        return context

    def _llm_analyze(self, alert: dict, context: dict) -> dict:
        prompt = f"""
        ë‹¹ì‹ ì€ SRE ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ Kubernetes ì¸ì‹œë˜íŠ¸ë¥¼ ë¶„ì„í•˜ì„¸ìš”.

        ## Alert
        {json.dumps(alert, indent=2)}

        ## Context
        {json.dumps(context, indent=2)}

        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
        1. Root Cause: ê·¼ë³¸ ì›ì¸ (1-2ë¬¸ì¥)
        2. Impact: ì˜í–¥ ë²”ìœ„ (ì„œë¹„ìŠ¤/ì‚¬ìš©ì)
        3. Remediation: ë³µêµ¬ ë‹¨ê³„ (ë²ˆí˜¸ ëª©ë¡)
        4. Confidence: ë¶„ì„ ì‹ ë¢°ë„ (0-100%)
        """

        response = self.llm.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )

        # ì‘ë‹µ íŒŒì‹± (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ íŒŒì‹± í•„ìš”)
        return self._parse_response(response.choices[0].message.content)
```

### ì¸ê³¼ ê´€ê³„ ê·¸ë˜í”„ (Causal Graph)

```yaml
# ì„œë¹„ìŠ¤ ì˜ì¡´ì„± ì •ì˜
apiVersion: v1
kind: ConfigMap
metadata:
  name: service-topology
data:
  topology.yaml: |
    services:
      - name: frontend
        depends_on: [api-gateway]
        metrics:
          - http_requests_total
          - http_request_duration_seconds

      - name: api-gateway
        depends_on: [order-service, user-service]
        metrics:
          - gateway_requests_total
          - gateway_latency_seconds

      - name: order-service
        depends_on: [postgres, redis]
        metrics:
          - order_processing_total
          - order_latency_seconds

      - name: postgres
        type: database
        metrics:
          - pg_connections
          - pg_query_duration_seconds

    # ì¥ì•  ì „íŒŒ ê·œì¹™
    propagation_rules:
      - if: postgres.pg_connections > 90%
        then: order-service.latency_increase
        confidence: 0.85

      - if: order-service.error_rate > 5%
        then: api-gateway.error_rate_increase
        confidence: 0.90
```

---

## ìë™ ë³µêµ¬ (Auto-Remediation)

### Runbook ìë™í™”

```yaml
# runbook-operator CRD
apiVersion: aiops.io/v1
kind: Runbook
metadata:
  name: pod-crash-loop-remediation
spec:
  trigger:
    alertname: PodCrashLoopBackOff
    severity: critical

  conditions:
    - type: pod_restart_count
      operator: ">"
      value: 5

  actions:
    - name: collect-diagnostics
      type: kubectl
      command: |
        kubectl logs {{ .pod }} -n {{ .namespace }} --previous > /tmp/crash-logs.txt
        kubectl describe pod {{ .pod }} -n {{ .namespace }} > /tmp/pod-describe.txt

    - name: check-resources
      type: prometheus
      query: |
        container_memory_working_set_bytes{
          pod="{{ .pod }}",
          namespace="{{ .namespace }}"
        } / container_spec_memory_limit_bytes > 0.95

    - name: remediate-oom
      type: kubectl
      condition: "{{ .check-resources.result == true }}"
      command: |
        kubectl patch deployment {{ .deployment }} -n {{ .namespace }} \
          -p '{"spec":{"template":{"spec":{"containers":[{
            "name":"{{ .container }}",
            "resources":{"limits":{"memory":"{{ .current_memory * 1.5 }}"}}
          }]}}}}'

    - name: restart-pod
      type: kubectl
      condition: "{{ .check-resources.result == false }}"
      command: |
        kubectl delete pod {{ .pod }} -n {{ .namespace }}

  notification:
    slack:
      channel: "#incidents"
      message: |
        ğŸ”§ Auto-remediation executed for {{ .pod }}
        Action: {{ .executed_action }}
        Result: {{ .result }}
```

### KEDA ê¸°ë°˜ ìë™ ìŠ¤ì¼€ì¼ë§

```yaml
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: aiops-autoscaler
spec:
  scaleTargetRef:
    name: order-service
  minReplicaCount: 2
  maxReplicaCount: 20
  triggers:
    # ì—ëŸ¬ìœ¨ ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§
    - type: prometheus
      metadata:
        serverAddress: http://prometheus:9090
        metricName: error_rate
        threshold: "5"
        query: |
          sum(rate(http_requests_total{
            status=~"5..",
            service="order-service"
          }[5m])) /
          sum(rate(http_requests_total{
            service="order-service"
          }[5m])) * 100

    # ì§€ì—° ì‹œê°„ ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§
    - type: prometheus
      metadata:
        metricName: p99_latency
        threshold: "1000"  # 1ì´ˆ
        query: |
          histogram_quantile(0.99,
            sum(rate(http_request_duration_seconds_bucket{
              service="order-service"
            }[5m])) by (le)
          ) * 1000
```

---

## ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ

### Grafana AIOps ëŒ€ì‹œë³´ë“œ

```json
{
  "title": "AIOps Overview",
  "panels": [
    {
      "title": "Anomaly Score",
      "type": "timeseries",
      "targets": [{
        "expr": "anomaly_score{job=\"aiops-detector\"}",
        "legendFormat": "{{ service }}"
      }],
      "thresholds": {
        "steps": [
          {"color": "green", "value": 0},
          {"color": "yellow", "value": 0.7},
          {"color": "red", "value": 0.9}
        ]
      }
    },
    {
      "title": "Auto-Remediation Actions",
      "type": "stat",
      "targets": [{
        "expr": "sum(increase(remediation_actions_total[24h]))"
      }]
    },
    {
      "title": "MTTR Trend",
      "type": "timeseries",
      "targets": [{
        "expr": "avg(incident_resolution_time_seconds) / 60"
      }],
      "unit": "minutes"
    }
  ]
}
```

---

## í•µì‹¬ ë©”íŠ¸ë¦­

### AIOps KPIs

| ë©”íŠ¸ë¦­ | ì„¤ëª… | ëª©í‘œ |
|--------|------|------|
| MTTD | íƒì§€ê¹Œì§€ ì‹œê°„ | < 5ë¶„ |
| MTTR | ë³µêµ¬ê¹Œì§€ ì‹œê°„ | < 30ë¶„ |
| ë…¸ì´ì¦ˆ ê°ì†Œìœ¨ | ì•Œë¦¼ í†µí•© íš¨ìœ¨ | > 80% |
| ìë™ ë³µêµ¬ìœ¨ | ìë™í™”ëœ í•´ê²° | > 40% |
| ì˜ˆì¸¡ ì •í™•ë„ | ì´ìƒ íƒì§€ ì •ë°€ë„ | > 90% |

### PromQL ì¿¼ë¦¬

```promql
# MTTD (íƒì§€ ì‹œê°„)
avg(incident_detection_time_seconds)

# MTTR (ë³µêµ¬ ì‹œê°„)
avg(incident_resolution_time_seconds)

# ì•Œë¦¼ ë…¸ì´ì¦ˆ ê°ì†Œìœ¨
1 - (
  sum(increase(alerts_deduplicated_total[24h])) /
  sum(increase(alerts_raw_total[24h]))
)

# ìë™ ë³µêµ¬ ì„±ê³µë¥ 
sum(increase(remediation_success_total[7d])) /
sum(increase(remediation_attempts_total[7d]))
```

---

## Anti-Patterns

| ì‹¤ìˆ˜ | ë¬¸ì œ | í•´ê²° |
|------|------|------|
| ë°ì´í„° ì‚¬ì¼ë¡œ | ìƒê´€ê´€ê³„ ë¶„ì„ ë¶ˆê°€ | OTel í†µí•© |
| ê³¼ë„í•œ ì•Œë¦¼ | ì•Œë¦¼ í”¼ë¡œ | ë…¸ì´ì¦ˆ í•„í„°ë§ |
| LLM ë§¹ì‹  | ì˜ëª»ëœ RCA | ì¸ê³¼ ëª¨ë¸ ë³‘í–‰ |
| ìë™í™” ê³¼ì‹  | ì˜ˆìƒì¹˜ ëª»í•œ ì¡°ì¹˜ | ìŠ¹ì¸ ê²Œì´íŠ¸ |
| ë°ì´í„° í­ì¦ | ë¹„ìš© ì¦ê°€ | ìƒ˜í”Œë§/ë³´ì¡´ ì •ì±… |

---

## ì²´í¬ë¦¬ìŠ¤íŠ¸

### AIOps Level 1 (ë°˜ì‘ì )
- [ ] OpenTelemetry í‘œì¤€í™”
- [ ] ì¤‘ì•™ ì§‘ì¤‘ì‹ ë¡œê¹…
- [ ] ê¸°ë³¸ ì•Œë¦¼ ì„¤ì •

### AIOps Level 2 (ì‚¬ì „ ì˜ˆë°©ì )
- [ ] ML ê¸°ë°˜ ì´ìƒ íƒì§€
- [ ] ì•Œë¦¼ ì¤‘ë³µ ì œê±°/ê·¸ë£¹í™”
- [ ] ì„œë¹„ìŠ¤ ì˜ì¡´ì„± ë§µí•‘

### AIOps Level 3 (ì˜ˆì¸¡ì )
- [ ] LLM ê¸°ë°˜ RCA
- [ ] ì¸ê³¼ ê´€ê³„ ê·¸ë˜í”„
- [ ] Runbook ìë™í™”

### AIOps Level 4 (ììœ¨ ìš´ì˜)
- [ ] ìë™ ë³µêµ¬ íŒŒì´í”„ë¼ì¸
- [ ] ì˜ˆì¸¡ì  ìŠ¤ì¼€ì¼ë§
- [ ] Self-Healing ì‹œìŠ¤í…œ

**ê´€ë ¨ agent**: `incident-responder`, `k8s-troubleshooter`
**ê´€ë ¨ skill**: `/observability`, `/alerting`

---

## Sources

- [Kubernetes Observability Trends 2026](https://www.usdsi.org/data-science-insights/kubernetes-observability-and-monitoring-trends-in-2026)
- [AI-Based Observability 2026](https://middleware.io/blog/how-ai-based-insights-can-change-the-observability/)
- [Modern Kubernetes Monitoring with AIOps](https://developers.redhat.com/articles/2025/12/17/modern-kubernetes-monitoring-metrics-tools-and-aiops)
- [LLMs for Root Cause Analysis](https://dzone.com/articles/llms-automated-root-cause-analysis-incident-response)
- [Observability AI Trends 2026](https://www.logicmonitor.com/blog/observability-ai-trends-2026)
- [Causal Reasoning in Observability](https://www.infoq.com/articles/causal-reasoning-observability/)
